{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c13bcdf4-27ca-4d9b-a93d-98c50d47d9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ai-edge-torch-nightly\n",
      "  Downloading ai_edge_torch_nightly-0.3.0.dev20250120-py3-none-any.whl (345 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.2/345.2 KB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=2.4.0 in /home/abheekp/kd/lib/python3.10/site-packages (from ai-edge-torch-nightly) (2.5.1)\n",
      "Requirement already satisfied: ai-edge-quantizer-nightly in /home/abheekp/kd/lib/python3.10/site-packages (from ai-edge-torch-nightly) (0.0.1.dev20240718)\n",
      "Collecting jax\n",
      "  Downloading jax-0.5.0-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/abheekp/kd/lib/python3.10/site-packages (from ai-edge-torch-nightly) (1.10.1)\n",
      "Collecting ai-edge-litert-nightly\n",
      "  Downloading ai_edge_litert_nightly-1.0.1.dev20250119-cp310-cp310-manylinux_2_17_x86_64.whl (2.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tabulate in /home/abheekp/kd/lib/python3.10/site-packages (from ai-edge-torch-nightly) (0.9.0)\n",
      "Collecting tf-nightly>=2.19.0.dev20241201\n",
      "  Downloading tf_nightly-2.19.0.dev20250118-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (641.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m641.6/641.6 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch-xla2[odml]>=0.0.1.dev20241201\n",
      "  Downloading torch_xla2-0.0.1.dev202412041639-py3-none-any.whl (76 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.7/76.7 KB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/abheekp/kd/lib/python3.10/site-packages (from ai-edge-torch-nightly) (1.26.4)\n",
      "Requirement already satisfied: safetensors in /home/abheekp/kd/lib/python3.10/site-packages (from ai-edge-torch-nightly) (0.4.5)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/abheekp/kd/lib/python3.10/site-packages (from tf-nightly>=2.19.0.dev20241201->ai-edge-torch-nightly) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/abheekp/kd/lib/python3.10/site-packages (from tf-nightly>=2.19.0.dev20241201->ai-edge-torch-nightly) (3.4.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/abheekp/kd/lib/python3.10/site-packages (from tf-nightly>=2.19.0.dev20241201->ai-edge-torch-nightly) (2.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/abheekp/kd/lib/python3.10/site-packages (from tf-nightly>=2.19.0.dev20241201->ai-edge-torch-nightly) (1.16.0)\n",
      "Requirement already satisfied: setuptools in /home/abheekp/kd/lib/python3.10/site-packages (from tf-nightly>=2.19.0.dev20241201->ai-edge-torch-nightly) (59.6.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/abheekp/kd/lib/python3.10/site-packages (from tf-nightly>=2.19.0.dev20241201->ai-edge-torch-nightly) (1.68.0)\n",
      "Requirement already satisfied: keras-nightly>=3.6.0.dev in /home/abheekp/kd/lib/python3.10/site-packages (from tf-nightly>=2.19.0.dev20241201->ai-edge-torch-nightly) (3.7.0.dev2024112003)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/abheekp/kd/lib/python3.10/site-packages (from tf-nightly>=2.19.0.dev20241201->ai-edge-torch-nightly) (4.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/abheekp/kd/lib/python3.10/site-packages (from tf-nightly>=2.19.0.dev20241201->ai-edge-torch-nightly) (1.16.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/abheekp/kd/lib/python3.10/site-packages (from tf-nightly>=2.19.0.dev20241201->ai-edge-torch-nightly) (3.12.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/abheekp/kd/lib/python3.10/site-packages (from tf-nightly>=2.19.0.dev20241201->ai-edge-torch-nightly) (0.37.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/abheekp/kd/lib/python3.10/site-packages (from tf-nightly>=2.19.0.dev20241201->ai-edge-torch-nightly) (1.6.3)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.4.0 in /home/abheekp/kd/lib/python3.10/site-packages (from tf-nightly>=2.19.0.dev20241201->ai-edge-torch-nightly) (0.4.1)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/abheekp/kd/lib/python3.10/site-packages (from tf-nightly>=2.19.0.dev20241201->ai-edge-torch-nightly) (0.6.0)\n",
      "Requirement already satisfied: tb-nightly~=2.19.0.a in /home/abheekp/kd/lib/python3.10/site-packages (from tf-nightly>=2.19.0.dev20241201->ai-edge-torch-nightly) (2.19.0a20241120)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/abheekp/kd/lib/python3.10/site-packages (from tf-nightly>=2.19.0.dev20241201->ai-edge-torch-nightly) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/abheekp/kd/lib/python3.10/site-packages (from tf-nightly>=2.19.0.dev20241201->ai-edge-torch-nightly) (2.5.0)\n",
      "Requirement already satisfied: packaging in /home/abheekp/kd/lib/python3.10/site-packages (from tf-nightly>=2.19.0.dev20241201->ai-edge-torch-nightly) (23.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/abheekp/kd/lib/python3.10/site-packages (from tf-nightly>=2.19.0.dev20241201->ai-edge-torch-nightly) (2.32.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/abheekp/kd/lib/python3.10/site-packages (from tf-nightly>=2.19.0.dev20241201->ai-edge-torch-nightly) (24.3.25)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /home/abheekp/kd/lib/python3.10/site-packages (from tf-nightly>=2.19.0.dev20241201->ai-edge-torch-nightly) (5.28.3)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/abheekp/kd/lib/python3.10/site-packages (from torch>=2.4.0->ai-edge-torch-nightly) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/abheekp/kd/lib/python3.10/site-packages (from torch>=2.4.0->ai-edge-torch-nightly) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/abheekp/kd/lib/python3.10/site-packages (from torch>=2.4.0->ai-edge-torch-nightly) (2.21.5)\n",
      "Requirement already satisfied: jinja2 in /home/abheekp/kd/lib/python3.10/site-packages (from torch>=2.4.0->ai-edge-torch-nightly) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/abheekp/kd/lib/python3.10/site-packages (from torch>=2.4.0->ai-edge-torch-nightly) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/abheekp/kd/lib/python3.10/site-packages (from torch>=2.4.0->ai-edge-torch-nightly) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/abheekp/kd/lib/python3.10/site-packages (from torch>=2.4.0->ai-edge-torch-nightly) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/abheekp/kd/lib/python3.10/site-packages (from torch>=2.4.0->ai-edge-torch-nightly) (3.1.0)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/abheekp/kd/lib/python3.10/site-packages (from torch>=2.4.0->ai-edge-torch-nightly) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/abheekp/kd/lib/python3.10/site-packages (from torch>=2.4.0->ai-edge-torch-nightly) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/abheekp/kd/lib/python3.10/site-packages (from torch>=2.4.0->ai-edge-torch-nightly) (9.1.0.70)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/abheekp/kd/lib/python3.10/site-packages (from torch>=2.4.0->ai-edge-torch-nightly) (1.13.1)\n",
      "Requirement already satisfied: networkx in /home/abheekp/kd/lib/python3.10/site-packages (from torch>=2.4.0->ai-edge-torch-nightly) (3.4.2)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/abheekp/kd/lib/python3.10/site-packages (from torch>=2.4.0->ai-edge-torch-nightly) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/abheekp/kd/lib/python3.10/site-packages (from torch>=2.4.0->ai-edge-torch-nightly) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/abheekp/kd/lib/python3.10/site-packages (from torch>=2.4.0->ai-edge-torch-nightly) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/abheekp/kd/lib/python3.10/site-packages (from torch>=2.4.0->ai-edge-torch-nightly) (12.4.127)\n",
      "Requirement already satisfied: filelock in /home/abheekp/kd/lib/python3.10/site-packages (from torch>=2.4.0->ai-edge-torch-nightly) (3.16.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/abheekp/kd/lib/python3.10/site-packages (from sympy==1.13.1->torch>=2.4.0->ai-edge-torch-nightly) (1.3.0)\n",
      "Collecting pytest\n",
      "  Using cached pytest-8.3.4-py3-none-any.whl (343 kB)\n",
      "Requirement already satisfied: immutabledict in /home/abheekp/kd/lib/python3.10/site-packages (from torch-xla2[odml]>=0.0.1.dev20241201->ai-edge-torch-nightly) (4.2.1)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.6/40.6 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting jaxlib<=0.5.0,>=0.5.0\n",
      "  Downloading jaxlib-0.5.0-cp310-cp310-manylinux2014_x86_64.whl (102.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.0/102.0 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /home/abheekp/kd/lib/python3.10/site-packages (from astunparse>=1.6.0->tf-nightly>=2.19.0.dev20241201->ai-edge-torch-nightly) (0.45.0)\n",
      "Requirement already satisfied: rich in /home/abheekp/kd/lib/python3.10/site-packages (from keras-nightly>=3.6.0.dev->tf-nightly>=2.19.0.dev20241201->ai-edge-torch-nightly) (13.9.4)\n",
      "Requirement already satisfied: namex in /home/abheekp/kd/lib/python3.10/site-packages (from keras-nightly>=3.6.0.dev->tf-nightly>=2.19.0.dev20241201->ai-edge-torch-nightly) (0.0.8)\n",
      "Requirement already satisfied: optree in /home/abheekp/kd/lib/python3.10/site-packages (from keras-nightly>=3.6.0.dev->tf-nightly>=2.19.0.dev20241201->ai-edge-torch-nightly) (0.13.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/abheekp/kd/lib/python3.10/site-packages (from requests<3,>=2.21.0->tf-nightly>=2.19.0.dev20241201->ai-edge-torch-nightly) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/abheekp/kd/lib/python3.10/site-packages (from requests<3,>=2.21.0->tf-nightly>=2.19.0.dev20241201->ai-edge-torch-nightly) (2024.8.30)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/abheekp/kd/lib/python3.10/site-packages (from requests<3,>=2.21.0->tf-nightly>=2.19.0.dev20241201->ai-edge-torch-nightly) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/abheekp/kd/lib/python3.10/site-packages (from requests<3,>=2.21.0->tf-nightly>=2.19.0.dev20241201->ai-edge-torch-nightly) (2.2.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/abheekp/kd/lib/python3.10/site-packages (from tb-nightly~=2.19.0.a->tf-nightly>=2.19.0.dev20241201->ai-edge-torch-nightly) (0.7.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/abheekp/kd/lib/python3.10/site-packages (from tb-nightly~=2.19.0.a->tf-nightly>=2.19.0.dev20241201->ai-edge-torch-nightly) (3.7)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/abheekp/kd/lib/python3.10/site-packages (from tb-nightly~=2.19.0.a->tf-nightly>=2.19.0.dev20241201->ai-edge-torch-nightly) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/abheekp/kd/lib/python3.10/site-packages (from jinja2->torch>=2.4.0->ai-edge-torch-nightly) (3.0.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /home/abheekp/kd/lib/python3.10/site-packages (from pytest->torch-xla2[odml]>=0.0.1.dev20241201->ai-edge-torch-nightly) (1.2.2)\n",
      "Collecting pluggy<2,>=1.5\n",
      "  Using cached pluggy-1.5.0-py3-none-any.whl (20 kB)\n",
      "Collecting tomli>=1\n",
      "  Using cached tomli-2.2.1-py3-none-any.whl (14 kB)\n",
      "Collecting iniconfig\n",
      "  Using cached iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/abheekp/kd/lib/python3.10/site-packages (from rich->keras-nightly>=3.6.0.dev->tf-nightly>=2.19.0.dev20241201->ai-edge-torch-nightly) (2.18.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/abheekp/kd/lib/python3.10/site-packages (from rich->keras-nightly>=3.6.0.dev->tf-nightly>=2.19.0.dev20241201->ai-edge-torch-nightly) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/abheekp/kd/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras-nightly>=3.6.0.dev->tf-nightly>=2.19.0.dev20241201->ai-edge-torch-nightly) (0.1.2)\n",
      "Installing collected packages: tomli, scipy, pluggy, iniconfig, ai-edge-litert-nightly, pytest, jaxlib, jax, torch-xla2, tf-nightly, ai-edge-torch-nightly\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.10.1\n",
      "    Uninstalling scipy-1.10.1:\n",
      "      Successfully uninstalled scipy-1.10.1\n",
      "  Attempting uninstall: tf-nightly\n",
      "    Found existing installation: tf_nightly 2.19.0.dev20241119\n",
      "    Uninstalling tf_nightly-2.19.0.dev20241119:\n",
      "      Successfully uninstalled tf_nightly-2.19.0.dev20241119\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install ai-edge-torch-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c717bafb-2c03-4eb3-ab22-caad9c13f50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/home/abheekp/kd/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -f-nightly (/home/abheekp/kd/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/home/abheekp/kd/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -f-nightly (/home/abheekp/kd/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting tensorflow==2.12.0\n",
      "  Using cached tensorflow-2.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/abheekp/kd/lib/python3.10/site-packages (from tensorflow==2.12.0) (1.68.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/abheekp/kd/lib/python3.10/site-packages (from tensorflow==2.12.0) (2.5.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/abheekp/kd/lib/python3.10/site-packages (from tensorflow==2.12.0) (18.1.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/abheekp/kd/lib/python3.10/site-packages (from tensorflow==2.12.0) (1.16.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/abheekp/kd/lib/python3.10/site-packages (from tensorflow==2.12.0) (3.12.1)\n",
      "Requirement already satisfied: jax>=0.3.15 in /home/abheekp/kd/lib/python3.10/site-packages (from tensorflow==2.12.0) (0.5.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/abheekp/kd/lib/python3.10/site-packages (from tensorflow==2.12.0) (0.37.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/abheekp/kd/lib/python3.10/site-packages (from tensorflow==2.12.0) (3.4.0)\n",
      "Requirement already satisfied: packaging in /home/abheekp/kd/lib/python3.10/site-packages (from tensorflow==2.12.0) (23.2)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/abheekp/kd/lib/python3.10/site-packages (from tensorflow==2.12.0) (24.3.25)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/abheekp/kd/lib/python3.10/site-packages (from tensorflow==2.12.0) (1.6.3)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in /home/abheekp/kd/lib/python3.10/site-packages (from tensorflow==2.12.0) (1.23.5)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /home/abheekp/kd/lib/python3.10/site-packages (from tensorflow==2.12.0) (1.14.1)\n",
      "Collecting keras<2.13,>=2.12.0\n",
      "  Using cached keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/abheekp/kd/lib/python3.10/site-packages (from tensorflow==2.12.0) (2.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /home/abheekp/kd/lib/python3.10/site-packages (from tensorflow==2.12.0) (2.12.0)\n",
      "Collecting tensorboard<2.13,>=2.12\n",
      "  Using cached tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/abheekp/kd/lib/python3.10/site-packages (from tensorflow==2.12.0) (4.9.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/abheekp/kd/lib/python3.10/site-packages (from tensorflow==2.12.0) (0.2.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/abheekp/kd/lib/python3.10/site-packages (from tensorflow==2.12.0) (4.25.5)\n",
      "Requirement already satisfied: setuptools in /home/abheekp/kd/lib/python3.10/site-packages (from tensorflow==2.12.0) (59.6.0)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/abheekp/kd/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.12.0) (0.45.0)\n",
      "Collecting jax>=0.3.15\n",
      "  Using cached jax-0.4.38-py3-none-any.whl (2.2 MB)\n",
      "Collecting jaxlib<=0.4.38,>=0.4.38\n",
      "  Using cached jaxlib-0.4.38-cp310-cp310-manylinux2014_x86_64.whl (101.7 MB)\n",
      "Requirement already satisfied: ml_dtypes>=0.4.0 in /home/abheekp/kd/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.1)\n",
      "Collecting jax>=0.3.15\n",
      "  Using cached jax-0.4.37-py3-none-any.whl (2.2 MB)\n",
      "Collecting jaxlib<=0.4.37,>=0.4.36\n",
      "  Using cached jaxlib-0.4.36-cp310-cp310-manylinux2014_x86_64.whl (100.3 MB)\n",
      "Collecting jax>=0.3.15\n",
      "  Using cached jax-0.4.36-py3-none-any.whl (2.2 MB)\n",
      "  Using cached jax-0.4.35-py3-none-any.whl (2.2 MB)\n",
      "Collecting jaxlib<=0.4.35,>=0.4.34\n",
      "  Using cached jaxlib-0.4.35-cp310-cp310-manylinux2014_x86_64.whl (87.3 MB)\n",
      "Requirement already satisfied: scipy>=1.10 in /home/abheekp/kd/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow==2.12.0) (1.15.1)\n",
      "Collecting jax>=0.3.15\n",
      "  Using cached jax-0.4.34-py3-none-any.whl (2.1 MB)\n",
      "  Using cached jax-0.4.33-py3-none-any.whl (2.1 MB)\n",
      "Collecting jaxlib<=0.4.33,>=0.4.33\n",
      "  Using cached jaxlib-0.4.33-cp310-cp310-manylinux2014_x86_64.whl (85.0 MB)\n",
      "Collecting jax>=0.3.15\n",
      "  Using cached jax-0.4.31-py3-none-any.whl (2.0 MB)\n",
      "  Using cached jax-0.4.30-py3-none-any.whl (2.0 MB)\n",
      "Collecting jaxlib<=0.4.30,>=0.4.27\n",
      "  Using cached jaxlib-0.4.30-cp310-cp310-manylinux2014_x86_64.whl (79.6 MB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/abheekp/kd/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.32.3)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.37.0-py2.py3-none-any.whl (209 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/abheekp/kd/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.1.3)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/abheekp/kd/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/abheekp/kd/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.7.2)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/abheekp/kd/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/abheekp/kd/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/abheekp/kd/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2024.8.30)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/abheekp/kd/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/abheekp/kd/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.0.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /home/abheekp/kd/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/abheekp/kd/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.2.2)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/home/abheekp/kd/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -f-nightly (/home/abheekp/kd/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: rsa, pyasn1-modules, keras, gast, cachetools, requests-oauthlib, jaxlib, google-auth, jax, google-auth-oauthlib, tensorboard, tensorflow\n",
      "  Attempting uninstall: keras\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -umpy (/home/abheekp/kd/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m    WARNING: Ignoring invalid distribution -f-nightly (/home/abheekp/kd/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: keras 3.6.0\n",
      "    Uninstalling keras-3.6.0:\n",
      "      Successfully uninstalled keras-3.6.0\n",
      "  Attempting uninstall: gast\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -umpy (/home/abheekp/kd/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m    WARNING: Ignoring invalid distribution -f-nightly (/home/abheekp/kd/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: gast 0.6.0\n",
      "    Uninstalling gast-0.6.0:\n",
      "      Successfully uninstalled gast-0.6.0\n",
      "  Attempting uninstall: jaxlib\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -umpy (/home/abheekp/kd/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m    WARNING: Ignoring invalid distribution -f-nightly (/home/abheekp/kd/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: jaxlib 0.5.0\n",
      "    Uninstalling jaxlib-0.5.0:\n",
      "      Successfully uninstalled jaxlib-0.5.0\n",
      "  Attempting uninstall: jax\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -umpy (/home/abheekp/kd/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m    WARNING: Ignoring invalid distribution -f-nightly (/home/abheekp/kd/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: jax 0.5.0\n",
      "    Uninstalling jax-0.5.0:\n",
      "      Successfully uninstalled jax-0.5.0\n",
      "  Attempting uninstall: tensorboard\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -umpy (/home/abheekp/kd/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m    WARNING: Ignoring invalid distribution -f-nightly (/home/abheekp/kd/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: tensorboard 2.18.0\n",
      "    Uninstalling tensorboard-2.18.0:\n",
      "      Successfully uninstalled tensorboard-2.18.0\n",
      "  Attempting uninstall: tensorflow\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -umpy (/home/abheekp/kd/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m    WARNING: Ignoring invalid distribution -f-nightly (/home/abheekp/kd/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: tensorflow 2.18.0\n",
      "    Uninstalling tensorflow-2.18.0:\n",
      "      Successfully uninstalled tensorflow-2.18.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/home/abheekp/kd/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -f-nightly (/home/abheekp/kd/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/home/abheekp/kd/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -f-nightly (/home/abheekp/kd/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/home/abheekp/kd/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -f-nightly (/home/abheekp/kd/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/home/abheekp/kd/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -f-nightly (/home/abheekp/kd/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/home/abheekp/kd/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -f-nightly (/home/abheekp/kd/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/home/abheekp/kd/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -f-nightly (/home/abheekp/kd/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/home/abheekp/kd/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -f-nightly (/home/abheekp/kd/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/home/abheekp/kd/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -f-nightly (/home/abheekp/kd/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/home/abheekp/kd/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -f-nightly (/home/abheekp/kd/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/home/abheekp/kd/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -f-nightly (/home/abheekp/kd/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/home/abheekp/kd/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -f-nightly (/home/abheekp/kd/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/home/abheekp/kd/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -f-nightly (/home/abheekp/kd/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed cachetools-5.5.0 gast-0.4.0 google-auth-2.37.0 google-auth-oauthlib-1.0.0 jax-0.4.30 jaxlib-0.4.30 keras-2.12.0 pyasn1-modules-0.4.1 requests-oauthlib-2.0.0 rsa-4.9 tensorboard-2.12.3 tensorflow-2.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tensorflow==2.12.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63c84c64-1cd2-4f09-97ef-aa46e11b35a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PJRT_DEVICE'] = 'CPU'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''  # Optionally disable CUDA\n",
    "!export USE_TORCH_XLA=0\n",
    "!export PJRT_DEVICE=CPU\n",
    "!export CUDA_VISIBLE_DEVICES=\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65c9f5ad-c41e-4485-9d4b-c44075253c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_91854/2760348886.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(CHECKPOINT_PATH, map_location=\"cpu\" )\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (128x5 and 4x48)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 128\u001b[0m\n\u001b[1;32m    125\u001b[0m sample_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 128\u001b[0m     pytorch_prob \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_input\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()  \u001b[38;5;66;03m# baseline PyTorch inference\u001b[39;00m\n\u001b[1;32m    130\u001b[0m edge_model \u001b[38;5;241m=\u001b[39m ai_edge_torch\u001b[38;5;241m.\u001b[39mconvert(\n\u001b[1;32m    131\u001b[0m     model\u001b[38;5;241m.\u001b[39meval(),\n\u001b[1;32m    132\u001b[0m     (sample_input,)  \u001b[38;5;66;03m# sample input as a tuple\u001b[39;00m\n\u001b[1;32m    133\u001b[0m )\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m##############################################################################\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# 4. Compare Inference Outputs\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m##############################################################################\u001b[39;00m\n",
      "File \u001b[0;32m~/kd/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/kd/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[8], line 84\u001b[0m, in \u001b[0;36mStudentModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     82\u001b[0m magnitude \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(torch\u001b[38;5;241m.\u001b[39msum(x \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m     83\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x, magnitude], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# [B, T, 4]\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m                 \u001b[38;5;66;03m# [B, T, hidden_dim]\u001b[39;00m\n\u001b[1;32m     85\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)                  \u001b[38;5;66;03m# [B, hidden_dim, T]\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemporal_blocks:\n",
      "File \u001b[0;32m~/kd/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/kd/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/kd/lib/python3.10/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/kd/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/kd/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/kd/lib/python3.10/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (128x5 and 4x48)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import ai_edge_torch\n",
    "\n",
    "# Suppress user warnings from the Transformer module (if any)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch.nn.modules.transformer\")\n",
    "\n",
    "##############################################################################\n",
    "# 1) Define StudentModel returning a single probability (via sigmoid)\n",
    "##############################################################################\n",
    "class PrecisionBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolution-based residual block for capturing detailed temporal dynamics.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size,\n",
    "                               padding=kernel_size // 2)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size,\n",
    "                               padding=kernel_size // 2)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        # Weighted residual connection\n",
    "        self.res_weight = nn.Parameter(torch.ones(1))\n",
    "        self.shortcut = (\n",
    "            nn.Conv1d(in_channels, out_channels, 1)\n",
    "            if in_channels != out_channels else nn.Identity()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.shortcut(x)\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = out + self.res_weight * identity\n",
    "        return F.relu(out)\n",
    "\n",
    "\n",
    "class TemporalAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-scale temporal attention for highlighting critical fall segments.\n",
    "    \"\"\"\n",
    "    def __init__(self, channels, reduction=8):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channels * 2, channels // reduction),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(channels // reduction, channels),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, t = x.size()\n",
    "        avg_pooled = self.avg_pool(x).view(b, c)\n",
    "        max_pooled = self.max_pool(x).view(b, c)\n",
    "\n",
    "        combined = torch.cat([avg_pooled, max_pooled], dim=1)\n",
    "        scale = self.fc(combined).view(b, c, 1)\n",
    "        return x * scale.expand_as(x)\n",
    "\n",
    "\n",
    "class StudentModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Student model: Single-modality (watch accelerometer).\n",
    "    Incorporates magnitude computation in place of (x, y, z) => (x, y, z, magnitude).\n",
    "    Uses a stack of PrecisionBlocks + TemporalAttention to capture fall patterns.\n",
    "\n",
    "    IMPORTANT CHANGE:\n",
    "      Now returns *only* a single probability from sigmoid, rather than (prob, feat).\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 input_channels=4,  # x, y, z, + magnitude\n",
    "                 hidden_dim=48,\n",
    "                 num_blocks=4,\n",
    "                 dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Sequential(\n",
    "            nn.Linear(input_channels, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate * 0.5)\n",
    "        )\n",
    "\n",
    "        # Stacked temporal blocks\n",
    "        self.temporal_blocks = nn.ModuleList([\n",
    "            PrecisionBlock(hidden_dim, hidden_dim, kernel_size=(2*i + 3))\n",
    "            for i in range(num_blocks)\n",
    "        ])\n",
    "\n",
    "        self.attention = TemporalAttention(channels=hidden_dim)\n",
    "\n",
    "        # Classification head\n",
    "        self.fall_confidence = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, 1)\n",
    "        )\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: [B, T, 3] => raw watch accelerometer data (x, y, z)\n",
    "        Returns:\n",
    "            output: [B] => final probability in [0, 1]\n",
    "        \"\"\"\n",
    "        # 1) Compute magnitude => shape [B, T, 1]\n",
    "        magnitude = torch.sqrt(torch.sum(x**2, dim=-1, keepdim=True))\n",
    "        x = torch.cat([x, magnitude], dim=-1)  # => [B, T, 4]\n",
    "\n",
    "        # 2) Project => [B, T, hidden_dim] => [B, hidden_dim, T]\n",
    "        x = self.input_proj(x)\n",
    "        x = x.transpose(1, 2)\n",
    "\n",
    "        # 3) Pass through multiple blocks + attention\n",
    "        for block in self.temporal_blocks:\n",
    "            x = block(x)\n",
    "            x = self.attention(x)\n",
    "\n",
    "        # 4) Global average pool => [B, hidden_dim]\n",
    "        student_feat = F.adaptive_avg_pool1d(x, 1).squeeze(-1)\n",
    "\n",
    "        # 5) Final linear => shape [B], then sigmoid => [B]\n",
    "        student_logits = self.fall_confidence(student_feat).squeeze(-1)\n",
    "        output_prob = self.sigmoid(student_logits)\n",
    "\n",
    "        return output_prob\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# 2) Instantiate Model & Load Weights (No Retraining Needed)\n",
    "##############################################################################\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Instantiate your model\n",
    "    model = StudentModel(\n",
    "        input_channels=4,\n",
    "        hidden_dim=48,\n",
    "        num_blocks=4,\n",
    "        dropout_rate=0.2\n",
    "    ).eval()\n",
    "\n",
    "    # (Optional) Load existing checkpoint\n",
    "    # If you have a trained checkpoint, do:\n",
    "    checkpoint = torch.load(\"student_checkpoint.pth\", map_location=\"cpu\")\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.eval()\n",
    "\n",
    "    ##############################################################################\n",
    "    # 3) Convert with AI Edge Torch\n",
    "    ##############################################################################\n",
    "    # Example input shape: [B=1, T=128, channels=3], but the model internally appends magnitude => 4\n",
    "    sample_input = torch.randn(1, 128, 3)\n",
    "\n",
    "    # Baseline PyTorch inference\n",
    "    with torch.no_grad():\n",
    "        pt_output = model(sample_input).numpy()  # shape [1]\n",
    "\n",
    "    # Convert to LiteRT\n",
    "    edge_model = ai_edge_torch.convert(model.eval(), (sample_input,))\n",
    "\n",
    "    # LiteRT inference\n",
    "    edge_output = edge_model(sample_input)  # shape [1]\n",
    "\n",
    "    # Compare\n",
    "    print(\"PyTorch prob:\", pt_output)\n",
    "    print(\"LiteRT prob:\", edge_output)\n",
    "    print(\"Close?\", np.allclose(pt_output, edge_output, atol=1e-4, rtol=1e-4))\n",
    "\n",
    "    ##############################################################################\n",
    "    # 4) Serialize to TFLite\n",
    "    ##############################################################################\n",
    "    edge_model.export(\"student_model.tflite\")\n",
    "    print(\"Model exported as 'student_model.tflite'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3457aa61-0fd5-4cbd-953a-84b7d1faa855",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kd",
   "language": "python",
   "name": "kd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
