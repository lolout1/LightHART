# Basic configuration
model: "Models.StudentTrans.LightTransformerStudent"
dataset: "smartfallmm"

# Model parameters - these are passed directly to the model
model_args:
  input_channels: 3     # watch accelerometer input (x, y, z)
  d_model: 128           # embedding dimension
  nhead: 4               # number of attention heads
  num_layers: 2          # number of transformer encoder layers
  dim_feedforward: 256   # feedforward dimension in transformer
  dropout: 0.3       # dropout rate for regularization

# Dataset arguments must match the exact structure expected by the dataset class
dataset_args:
  mode: "sliding_window"        # pooling mode
  max_length: 128         # sequence length
  task: "fd"              # task: fall detection
  modalities: ["accelerometer"]  # only accelerometer data
  age_group: ["young"]
  sensors: ["watch"]
  normalize: true         # normalize input data

# Subject IDs as a flat list for the argument parser
subjects:
  - 29
  - 30
  - 31
  - 32
  - 33
  - 34
  - 35
  - 36
  - 37
  - 38
  - 39
  - 43
  - 44
  - 45
  - 46

# Training parameters that match main4.py arguments exactly
batch_size: 16
test_batch_size: 16 
val_batch_size: 16
num_epoch: 150
start_epoch: 0

# Optimizer settings that match the argument parser
optimizer: "adamw"
base_lr: 0.001
weight_decay: 0.0004

# Device configuration as expected by the script
device: [0]

# Feeder settings that match main4.py's requirements
feeder: "Feeder.Make_Dataset.UTD_mm"
train_feeder_args:
  batch_size: 16
val_feeder_args:
  batch_size: 16
test_feeder_args:
  batch_size: 16

# Additional training settings
num_worker: 4
seed: 42
include_val: true
print_log: true
phase: "train"

# Loss function configuration 
loss: "torch.nn.BCELoss"  # Binary Cross-Entropy Loss
loss_args: {}

# Scheduler settings
scheduler: "cosine"
scheduler_args:
  warmup_epochs: 10
